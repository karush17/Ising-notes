\BOOKMARK [1][-]{section.1}{Notation}{}% 1
\BOOKMARK [1][-]{section.2}{Introduction}{}% 2
\BOOKMARK [1][-]{section.3}{Related Work}{}% 3
\BOOKMARK [2][-]{subsection.3.1}{Hierarchical Reinforcement Learning}{section.3}% 4
\BOOKMARK [3][-]{subsubsection.3.1.1}{Temporal Abstraction}{subsection.3.1}% 5
\BOOKMARK [3][-]{subsubsection.3.1.2}{Option-based Hierarchies}{subsection.3.1}% 6
\BOOKMARK [3][-]{subsubsection.3.1.3}{Hierarchical Control}{subsection.3.1}% 7
\BOOKMARK [2][-]{subsection.3.2}{Ising Models}{section.3}% 8
\BOOKMARK [3][-]{subsubsection.3.2.1}{Energy-based Reinforcement Learning}{subsection.3.2}% 9
\BOOKMARK [3][-]{subsubsection.3.2.2}{Ising Model Learning}{subsection.3.2}% 10
\BOOKMARK [1][-]{section.4}{The Ising Model}{}% 11
\BOOKMARK [1][-]{section.5}{Ising Networks}{}% 12
\BOOKMARK [2][-]{subsection.5.1}{The Spin-based Objective}{section.5}% 13
\BOOKMARK [2][-]{subsection.5.2}{Learning Spin Values of Hierarchies}{section.5}% 14
\BOOKMARK [1][-]{section.6}{Implementation Details}{}% 15
\BOOKMARK [2][-]{subsection.6.1}{Continuous Control}{section.6}% 16
\BOOKMARK [3][-]{subsubsection.6.1.1}{State-based Learning}{subsection.6.1}% 17
\BOOKMARK [3][-]{subsubsection.6.1.2}{Learning from Pixels}{subsection.6.1}% 18
\BOOKMARK [2][-]{subsection.6.2}{Discrete Control}{section.6}% 19
\BOOKMARK [3][-]{subsubsection.6.2.1}{Atari 2600 Games}{subsection.6.2}% 20
\BOOKMARK [3][-]{subsubsection.6.2.2}{Mazelab}{subsection.6.2}% 21
\BOOKMARK [2][-]{subsection.6.3}{Multi-Agent Learning}{section.6}% 22
\BOOKMARK [1][-]{section.7}{Propositions}{}% 23
\BOOKMARK [1][-]{section.8}{Intuition for Spin Values}{}% 24
