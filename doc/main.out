\BOOKMARK [1][-]{section.1}{Notation}{}% 1
\BOOKMARK [1][-]{section.2}{Introduction}{}% 2
\BOOKMARK [1][-]{section.3}{Related Work}{}% 3
\BOOKMARK [2][-]{subsection.3.1}{Hierarchical Reinforcement Learning}{section.3}% 4
\BOOKMARK [3][-]{subsubsection.3.1.1}{Temporal Abstraction}{subsection.3.1}% 5
\BOOKMARK [3][-]{subsubsection.3.1.2}{Option-based Hierarchies}{subsection.3.1}% 6
\BOOKMARK [3][-]{subsubsection.3.1.3}{Hierarchical Control}{subsection.3.1}% 7
\BOOKMARK [2][-]{subsection.3.2}{Ising Models}{section.3}% 8
\BOOKMARK [3][-]{subsubsection.3.2.1}{Energy-based Reinforcement Learning}{subsection.3.2}% 9
\BOOKMARK [3][-]{subsubsection.3.2.2}{Ising Model Learning}{subsection.3.2}% 10
\BOOKMARK [1][-]{section.4}{The Ising Model}{}% 11
\BOOKMARK [1][-]{section.5}{Ising Networks}{}% 12
\BOOKMARK [2][-]{subsection.5.1}{The Spin-based Objective}{section.5}% 13
\BOOKMARK [2][-]{subsection.5.2}{Learning Spin Values of Hierarchies}{section.5}% 14
\BOOKMARK [1][-]{section.6}{Intuition for Spin Values}{}% 15
\BOOKMARK [1][-]{section.7}{Implementation Details}{}% 16
\BOOKMARK [2][-]{subsection.7.1}{Continuous Control}{section.7}% 17
\BOOKMARK [3][-]{subsubsection.7.1.1}{State-based Learning}{subsection.7.1}% 18
\BOOKMARK [3][-]{subsubsection.7.1.2}{Learning from Pixels}{subsection.7.1}% 19
\BOOKMARK [2][-]{subsection.7.2}{Discrete Control}{section.7}% 20
\BOOKMARK [3][-]{subsubsection.7.2.1}{Atari 2600 Games}{subsection.7.2}% 21
\BOOKMARK [3][-]{subsubsection.7.2.2}{Mazelab}{subsection.7.2}% 22
\BOOKMARK [2][-]{subsection.7.3}{Multi-Agent Learning}{section.7}% 23
\BOOKMARK [1][-]{section.8}{Propositions}{}% 24
