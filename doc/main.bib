@misc{hdqn,
    title={Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation},
    author={Tejas D. Kulkarni and Karthik R. Narasimhan and Ardavan Saeedi and Joshua B. Tenenbaum},
    year={2016},
    eprint={1604.06057},
}

@misc{dsn,
    title={Deep Successor Reinforcement Learning},
    author={Tejas D. Kulkarni and Ardavan Saeedi and Simanta Gautam and Samuel J. Gershman},
    year={2016},
    eprint={1606.02396},
}

@MISC{temp,
    author = {Doina Precup},
    title = {Temporal Abstraction in Reinforcement Learning},
    year = {2000}
}

@misc{
learningtemp,
title={Learning Temporal Abstraction with Information-theoretic Constraints for Hierarchical Reinforcement Learning},
author={Wenshan Wang and Yaoyu Hu and Sebastian Scherer},
year={2020},
}

@misc{stochastic,
    title={Stochastic Neural Networks for Hierarchical Reinforcement Learning},
    author={Carlos Florensa and Yan Duan and Pieter Abbeel},
    year={2017},
    eprint={1704.03012},
}

@book{sutton,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  title = {Reinforcement Learning: An Introduction},
  year = {2018 }
}

@inproceedings{utility,
  title={The utility of temporal abstraction in reinforcement learning.},
  author={Jong, Nicholas K and Hester, Todd and Stone, Peter},
  booktitle={AAMAS (1)},
  year={2008}
}

@article{self,
  title={Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings},
  author={Co-Reyes, John D and Liu, YuXuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1806.02813},
  year={2018}
}

@inproceedings{
hippo,
title={Sub-policy Adaptation for Hierarchical Reinforcement Learning},
author={Alexander Li and Carlos Florensa and Ignasi Clavera and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2020},
}

@incollection{language,
title = {Language as an Abstraction for Hierarchical Deep Reinforcement Learning},
author = {Jiang, YiDing and Gu, Shixiang (Shane) and Murphy, Kevin P and Finn, Chelsea},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019}
}

@inproceedings{program,
  title={State abstraction for programmable reinforcement learning agents},
  author={Andre, David and Russell, Stuart J},
  booktitle={AAAI/IAAI},
  year={2002}
}

@inproceedings{maxq,
  title={State abstraction in MAXQ hierarchical reinforcement learning},
  author={Dietterich, Thomas G},
  booktitle={Advances in Neural Information Processing Systems},
  year={2000}
}

@inproceedings{lifelong,
  title={State abstractions for lifelong reinforcement learning},
  author={Abel, David and Arumugam, Dilip and Lehnert, Lucas and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{evolutionary,
  title={Evolutionary tile coding: An automated state abstraction algorithm for reinforcement learning},
  author={Lin, Stephen and Wright, Robert},
  booktitle={Proceedings of the 8th AAAI Conference on Abstraction, Reformulation, and Approximation},
  year={2010}
}

@incollection{maven,
title = {MAVEN: Multi-Agent Variational Exploration},
author = {Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019}
}

@misc{option,
    title={The Option-Critic Architecture},
    author={Pierre-Luc Bacon and Jean Harb and Doina Precup},
    year={2016},
    eprint={1609.05140}
}

@misc{doubleoption,
    title={DAC: The Double Actor-Critic Architecture for Learning Options},
    author={Shangtong Zhang and Shimon Whiteson},
    year={2019},
    eprint={1904.12691}
}

@misc{soac,
    title={SOAC: The Soft Option Actor-Critic Architecture},
    author={Chenghao Li and Xiaoteng Ma and Chongjie Zhang and Jun Yang and Li Xia and Qianchuan Zhao},
    year={2020},
    eprint={2006.14363}
}

@misc{mpc,
    title={Modulated Policy Hierarchies},
    author={Alexander Pashevich and Danijar Hafner and James Davidson and Rahul Sukthankar and Cordelia Schmid},
    year={2018},
    eprint={1812.00025}
}

@misc{termination,
    title={The Termination Critic},
    author={Anna Harutyunyan and Will Dabney and Diana Borsa and Nicolas Heess and Remi Munos and Doina Precup},
    year={2019},
    eprint={1902.09996}
}

@misc{sac,
    title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
    author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
    year={2018},
    eprint={1801.01290}
}

@misc{sql,
    title={Reinforcement Learning with Deep Energy-Based Policies},
    author={Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine},
    year={2017},
    eprint={1702.08165}
}

@misc{control,
    title={MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies},
    author={Xue Bin Peng and Michael Chang and Grace Zhang and Pieter Abbeel and Sergey Levine},
    year={2019},
    archivePrefix={arXiv}
}

@article{quadruped,
   title={Hierarchical Reinforcement Learning for Quadruped Locomotion},
   journal={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
   author={Jain, Deepali and Iscen, Atil and Caluwaerts, Ken},
   year={2019}
}

@article{diversity,
   title={Diversity-Driven Extensible Hierarchical Reinforcement Learning},
   volume={33},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   author={Song, Yuhang and Wang, Jianyi and Lukasiewicz, Thomas and Xu, Zhenghua and Xu, Mai},
   year={2019}
}

@misc{lsp,
    title={Latent Space Policies for Hierarchical Reinforcement Learning},
    author={Tuomas Haarnoja and Kristian Hartikainen and Pieter Abbeel and Sergey Levine},
    year={2018},
    archivePrefix={arXiv}
}

@misc{embedding,
    title={Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement Learning},
    author={Sainbayar Sukhbaatar and Emily Denton and Arthur Szlam and Rob Fergus},
    year={2018},
    archivePrefix={arXiv}
}

@misc{kl,
    title={Exploiting Hierarchy for Learning and Transfer in KL-regularized RL},
    author={Dhruva Tirumala and Hyeonwoo Noh and Alexandre Galashov and Leonard Hasenclever and Arun Ahuja and Greg Wayne and Razvan Pascanu and Yee Whye Teh and Nicolas Heess},
    year={2019},
    archivePrefix={arXiv}
}

@article{compositional,
   title={Compositional Transfer in Hierarchical Reinforcement Learning},
   journal={Robotics: Science and Systems XVI},
   author={Wulfmeier, Markus and Abdolmaleki, Abbas and Hafner, Roland and Tobias Springenberg, Jost and Neunert, Michael and Siegel, Noah and Hertweck, Tim and Lampe, Thomas and Heess, Nicolas and Riedmiller, Martin},
   year={2020}
}

@misc{combinatorial,
    title={Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning},
    author={Qiang Ma and Suwen Ge and Danyang He and Darshan Thaker and Iddo Drori},
    year={2019},
    archivePrefix={arXiv}
}

@misc{advantage,
    title={Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization},
    author={Takayuki Osa and Voot Tangkaratt and Masashi Sugiyama},
    year={2019},
    archivePrefix={arXiv}
}

@INPROCEEDINGS{energy,
    author = {Yann LeCun and Sumit Chopra and Raia Hadsell and Fu Jie Huang and et al.},
    title = {A tutorial on energy-based learning},
    booktitle = {PREDICTING STRUCTURED DATA},
    year = {2006}
}

@misc{curl,
    title={CURL: Contrastive Unsupervised Representations for Reinforcement Learning},
    author={Aravind Srinivas and Michael Laskin and Pieter Abbeel},
    year={2020},
    archivePrefix={arXiv}
}

@misc{rad,
    title={Reinforcement Learning with Augmented Data},
    author={Michael Laskin and Kimin Lee and Adam Stooke and Lerrel Pinto and Pieter Abbeel and Aravind Srinivas},
    year={2020},
    archivePrefix={arXiv}
}

@article{energy-rl,
author = {Sallans, Brian and Hinton, Geoffrey E.},
title = {Reinforcement Learning with Factored States and Actions},
year = {2004},
journal = {The Journal of Machine Learning Research}
}

@article{overcomplete,
author = {Teh, Yee Whye and Welling, Max and Osindero, Simon and Hinton, Geoffrey E.},
title = {Energy-Based Models for Sparse Overcomplete Representations},
year = {2003},
journal = {The Journal of Machine Learning Research}
}

@misc{mellow,
    title={An Alternative Softmax Operator for Reinforcement Learning},
    author={Kavosh Asadi and Michael L. Littman},
    year={2016},
    archivePrefix={arXiv}
}

@misc{inverse,
    title={A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models},
    author={Chelsea Finn and Paul Christiano and Pieter Abbeel and Sergey Levine},
    year={2016},
    archivePrefix={arXiv}
}

@InProceedings{ac,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {Nicolas Heess and David Silver and Yee Whye Teh},
  year = 	 {2013},
  series = 	 {Proceedings of Machine Learning Research},
}

@book{david,
author = {MacKay, David J. C.},
title = {Information Theory, Inference \& Learning Algorithms},
year = {2002},
publisher = {Cambridge University Press}
}

@misc{energy-hier,
    title={Near-Optimal Representation Learning for Hierarchical Reinforcement Learning},
    author={Ofir Nachum and Shixiang Gu and Honglak Lee and Sergey Levine},
    year={2018},
    archivePrefix={arXiv}
}

@article{intro,
  title={An introduction to the Ising model},
  author={Cipra, Barry A},
  journal={The American Mathematical Monthly},
  year={1987}
}

@article{spin,
  title={The spin-spin correlation function in the two-dimensional Ising model in a magnetic field at T= Tc},
  author={Delfino, G and Mussardo, G},
  journal={Nuclear Physics B},
  year={1995}
}

@article{ising-energy,
   title={Non-equilibrium relaxation and interface energy of the Ising model},
   journal={Physica A: Statistical Mechanics and its Applications},
   author={Ito, Nobuyasu},
   year={1993}
}

@article{scaling,
    author = "Kadanoff, L.P.",
    title = "{Scaling laws for Ising models near T(c)}",
    year = "1966"
}

@article{field,
    author = "Wu, Tai Tsun and McCoy, Barry M. and Tracy, Craig A. and Barouch, Eytan",
    title = "{Spin spin correlation functions for the two-dimensional Ising model: Exact theory in the scaling region}",
    journal = "Phys. Rev. B",
    year = "1976"
}

@article{fast,
  title={Fast algorithm for the simulation of Ising models},
  author={Herrmann, HJ},
  journal={Journal of statistical physics},
  year={1986}
}

@incollection{exact,
title = {Efficient Exact Inference in Planar Ising Models},
author = {Nicol N. Schraudolph and Dmitry Kamenetsky},
booktitle = {Advances in Neural Information Processing Systems 21},
year = {2009}
}

@misc{convergence,
    title={Convergence Rates of Biased Stochastic Optimization for Learning Sparse Ising Models},
    author={Jean Honorio},
    year={2012},
    archivePrefix={arXiv}
}

@article{learn-critic,
author = {Morningstar, Alan and Melko, Roger G.},
title = {Deep Learning the Ising Model near Criticality},
year = {2017},
journal = {J. Mach. Learn. Res.}
}

@article{learn-param,
  title={Optimal structure and parameter learning of Ising models},
  author={Lokhov, Andrey Y and Vuffray, Marc and Misra, Sidhant and Chertkov, Michael},
  journal={Science advances},
  year={2018}
}

@article{rbm,
   title={Restricted Boltzmann machines for the long range Ising models},
   journal={Modern Physics Letters B},
   author={Aoki, Ken-Ichi and Kobayashi, Tamao},
   year={2016}
}

@misc{real,
    title={Ising models for networks of real neurons},
    author={Gasper Tkacik and Elad Schneidman and Michael J Berry II and William Bialek},
    year={2006},
    archivePrefix={arXiv}
}

@article{transform,
author = {Yoshioka, Nobuyuki and Akagi, Yutaka and Katsura, Hosho},
year = {2019},
title = {Transforming generalized Ising models into Boltzmann machines},
journal = {Physical Review E},
}

@book{book, title={Analytical Mechanics}, publisher={Cambridge University Press}, author={Hand, Louis N. and Finch, Janet D.}, year={1998}}

@book{thompson,
author = {Colin J. Thompson},
 publisher = {Princeton University Press},
 title = {Mathematical Statistical Mechanics},
 year = {1972}
}

@article {stats,
	author = {Gregory H. Wannier},
	title = {Statistical Physics},
	year = {1967},
	publisher = {American Association for the Advancement of Science}
}

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  publisher = {IROS},
  title = {MuJoCo: A physics engine for model-based control.}, year = 2012
}

@misc{dm,
    title={DeepMind Control Suite},
    author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
    year={2018},
    archivePrefix={arXiv}
}

@article{dreamer,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@article{ppo,
  added-at = {2019-12-16T18:31:56.000+0100},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {CoRR},
  timestamp = {2019-12-18T21:15:59.000+0100},
  title = {Proximal Policy Optimization Algorithms.},
  volume = {abs/1707.06347},
  year = 2017
}

@Article{ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Manfred Otto Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  journal={CoRR},
  year={2015},
  volume={abs/1509.02971}
}

@article{td3,
  author    = {Scott Fujimoto and
               Herke van Hoof and
               David Meger},
  title     = {Addressing Function Approximation Error in Actor-Critic Methods},
  journal   = {CoRR},
  volume    = {abs/1802.09477},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1802.09477},
  timestamp = {Sat, 28 Sep 2019 00:58:01 +0200},
}

@misc{es,
    title={Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
    author={Tim Salimans and Jonathan Ho and Xi Chen and Szymon Sidor and Ilya Sutskever},
    year={2017},
    eprint={1703.03864},
    archivePrefix={arXiv},
}

@misc{gym,
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
title = {OpenAI Gym},
  year = 2016
}

@article{emix,
  title={Energy-based Surprise Minimization for Multi-Agent Value Factorization},
  author={Suri, Karush and Shi, Xiao Qi and Plataniotis, Konstantinos and Lawryshyn, Yuri},
  journal={arXiv preprint arXiv:2009.09842},
  year={2020}
}

@article{esac,
author = {Suri, Karush and Shi, Xiao and Plataniotis, Konstantinos and Lawryshyn, Yuri},
year = {2020},
title = {Evolve To Control: Evolution-based Soft Actor-Critic for Scalable Reinforcement Learning},
  journal={arXiv preprint},

}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
}

@inproceedings{vb,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in neural information processing systems},
  year={2016}
}

@inproceedings{relu,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={ICML},
  year={2010}
}

@article{sacae,
  title={Improving sample efficiency in model-free reinforcement learning from images},
  author={Yarats, Denis and Zhang, Amy and Kostrikov, Ilya and Amos, Brandon and Pineau, Joelle and Fergus, Rob},
  journal={arXiv preprint arXiv:1910.01741},
  year={2019}
}

@misc{mazelab,
      author = {Zuo, Xingdong},
      title = {mazelab: A customizable framework to create maze and gridworld environments.},
      year = {2018},
      journal = {GitHub repository}
    }
    
@article{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  journal={arXiv preprint arXiv:1710.02298},
  year={2017}
}

@article{dqn,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal = {Nature},
  year = 2015
}

@inproceedings{acktr,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  year={2017}
}

@inproceedings{a2c,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  year={2016}
}

@misc{kostrikov,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  journal = {GitHub repository}
}

@misc{gen,
    title={Reinforcement Learning Generalization with Surprise Minimization},
    author={Jerry Zikun Chen},
    year={2020},
    eprint={2004.12399},
    archivePrefix={arXiv}
}
 
@inproceedings{qmix,
  title = "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning",
  author = "Tabish Rashid and Mikayel Samvelyan and Christian Schroeder de Witt and Gregory Farquhar and Jakob Foerster and Shimon Whiteson",
  year = "2018",
  booktitle = "ICML 2018: Proceedings of the Thirty-Fifth International Conference on Machine Learning"
}   
 
@misc{coma,
    title={Counterfactual Multi-Agent Policy Gradients},
    author={Jakob Foerster and Gregory Farquhar and Triantafyllos Afouras and Nantas Nardelli and Shimon Whiteson},
    year={2017},
    eprint={1705.08926},
    archivePrefix={arXiv}
}

@INPROCEEDINGS{iql,
    author = {Ming Tan},
    title = {Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents},
    booktitle = {In Proceedings of the Tenth International Conference on Machine Learning},
    year = {1993}
}

@inproceedings{vdn,
author = {Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z. and Tuyls, Karl and Graepel, Thore},
title = {Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
year = {2018},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2085–2087},
series = {AAMAS ’18}
}

@misc{smac,
    title={The StarCraft Multi-Agent Challenge},
    author={Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philip H. S. Torr and Jakob Foerster and Shimon Whiteson},
    year={2019},
    eprint={1902.04043},
    archivePrefix={arXiv}
}

@article{smirl,
  title={SMiRL: Surprise Minimizing RL in Entropic Environments},
  author={Berseth, Glen and Geng, Daniel and Devin, Coline and Jayaraman, Dinesh and Finn, Chelsea and Levine, Sergey},
  year={2019}
}

@inproceedings{lipschitz,
  title={Generalization error bounds for noisy, iterative algorithms},
  author={Pensia, Ankit and Jog, Varun and Loh, Po-Ling},
  booktitle={2018 IEEE International Symposium on Information Theory (ISIT)},
  year={2018}
}








   